### bitsandbytes

There is a process called quantization that means most of the llm models are in 16 bits then using bitsandbytes we will quantize that to 4 Bits

### Transformers

We can interact with huggingface library.

### Embedding

sentence_transformers
